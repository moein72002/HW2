{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61d95477",
   "metadata": {},
   "source": [
    "# Course Overview and Lesson Structure\n",
    "\n",
    "**Dear Students,**\n",
    "\n",
    "**Welcome to the Machine Learning Course - Fall 2025!**  \n",
    "We are thrilled to have you join us as we dive into the fascinating world of machine learning. Throughout this semester, you will gain hands-on experience with the most widely used algorithms, explore their practical applications, and build projects that showcase your understanding of key ML concepts. This course is designed to not only provide you with theoretical knowledge but also prepare you to tackle real-world problems with confidence.\n",
    "\n",
    "---\n",
    "\n",
    "### **Academic Integrity: Our Commitment to Ethical Learning**\n",
    "\n",
    "In this course, academic integrity is the foundation of our learning community. To ensure fairness and promote an environment of trust, all students are expected to adhere to the following principles:\n",
    "\n",
    "#### **1. Originality in Code**\n",
    "- Your submitted code must be **entirely your own work**.\n",
    "- **Collaboration is encouraged**, but sharing or copying code directly from peers or external sources is strictly prohibited.  \n",
    "- **External resources**, such as forums or online guides, may be consulted for reference, but any borrowed code must be **properly cited** in your submission.\n",
    "\n",
    "#### **2. Honesty in Written Work**\n",
    "- For conceptual questions, your answers should reflect your **own understanding** of the material.\n",
    "- Copying text from outside sources or using automated tools to generate responses is not allowed without proper attribution.\n",
    "- Be sure to **cite** all sources used for research or inspiration in both written and coding assignments.\n",
    "\n",
    "**Violation of these guidelines** may result in penalties, including the potential loss of assignment points.\n",
    "\n",
    "---\n",
    "\n",
    "### **Understanding and Communicating Results**\n",
    "\n",
    "In machine learning, writing accurate code is only one part of the learning process. It is equally important to understand and communicate the **implications of your results**. As you work through the assignments, make sure to:\n",
    "\n",
    "- **Comment your code** thoroughly to ensure clarity for yourself and others.\n",
    "- Provide a **detailed explanation** of the results you obtain, including:\n",
    "  - What the results tell you about the problem or dataset.\n",
    "  - Any patterns, trends, or anomalies you observe.\n",
    "  - The significance of your findings and potential next steps in improving the model.\n",
    "\n",
    "Clear, well-documented work will help demonstrate a deep understanding of the concepts you are applying.\n",
    "\n",
    "---\n",
    "\n",
    "### **We're Here to Support You**\n",
    "\n",
    "This semester, our teaching team is dedicated to making your learning experience engaging and meaningful. If you ever have questions about the material, assignments, or anything related to the course, please don't hesitate to reach out. We're here to guide you and ensure you succeed.\n",
    "\n",
    "We hope this course inspires your passion for machine learning and helps you build the skills to thrive in the field. Let's make this a great semester together!\n",
    "\n",
    "**Best Wishes,**  \n",
    "*The Machine Learning Teaching Team*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5ae396",
   "metadata": {},
   "source": [
    "# ML02 - Machine Learning Fall 2025\n",
    "\n",
    "- **Name:** `Your Full Name`\n",
    "- **Student ID:** `Your Student ID`\n",
    "\n",
    "---\n",
    "\n",
    "### Submission Deadline: **December 05, 2025**\n",
    "#### Submit your assignment via Microsoft Teams.\n",
    "#### File Naming Format: `ML02_LASTNAME_STUDENTID.ipynb`\n",
    "\n",
    "---\n",
    "\n",
    "### *Instructions for Completing the Problem Set:*\n",
    "\n",
    "- The problem set includes both coding and written response questions. For coding tasks, complete all code blocks marked with `YOUR CODE HERE`.\n",
    "  \n",
    "- For written answers, replace the placeholder text `[Your answer here]` with your response.\n",
    "\n",
    "If you have any questions or need further assistance, feel free to reach out to me via Telegram:\n",
    "\n",
    "* [Mohammadreza Mohammadhashemi](https://t.me/mrmh1380)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3521ae6",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "\n",
    "In this assignment, you will work with **THREE different datasets** to explore binary classification, multiclass classification, and multilabel classification problems:\n",
    "\n",
    "### 1. Binary Classification: Heart Disease Dataset\n",
    "This dataset contains medical records to predict whether a patient has heart disease (binary: 0 or 1).\n",
    "\n",
    "**Features include:**\n",
    "- Age, Sex, Chest Pain Type (cp)\n",
    "- Resting Blood Pressure (trestbps)\n",
    "- Cholesterol (chol)\n",
    "- Fasting Blood Sugar (fbs)\n",
    "- Resting ECG results (restecg)\n",
    "- Maximum Heart Rate (thalach)\n",
    "- Exercise Induced Angina (exang)\n",
    "- ST Depression (oldpeak)\n",
    "- Slope, ca, thal\n",
    "\n",
    "**Target:** `target` (0 = no disease, 1 = disease)\n",
    "\n",
    "**Dataset Source:** UCI Heart Disease Dataset\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Multiclass Classification: Wine Quality Dataset\n",
    "This dataset contains physicochemical properties of wines to predict wine quality ratings (multiclass: quality scores from 3 to 9).\n",
    "\n",
    "**Features include:**\n",
    "- Fixed acidity, Volatile acidity\n",
    "- Citric acid, Residual sugar\n",
    "- Chlorides, Free sulfur dioxide\n",
    "- Total sulfur dioxide, Density\n",
    "- pH, Sulphates, Alcohol\n",
    "\n",
    "**Target:** `quality` (integer from 3 to 9)\n",
    "\n",
    "**Dataset Source:** UCI Wine Quality Dataset\n",
    "\n",
    "---\n",
    "\n",
    "### 3. Multilabel Classification: Movie Genre Dataset\n",
    "This dataset contains movie descriptions and metadata to predict multiple genres that can be simultaneously assigned to a movie.\n",
    "\n",
    "**Features include:**\n",
    "- Movie title\n",
    "- Plot summary/description (text)\n",
    "- Release year\n",
    "- Duration\n",
    "- Director, Cast\n",
    "\n",
    "**Target:** Multiple genres (e.g., Action, Comedy, Drama, Thriller, etc.) - a movie can belong to multiple genres simultaneously\n",
    "\n",
    "**Dataset Source:** IMDB/Kaggle Movie Dataset or create synthetic multilabel dataset\n",
    "\n",
    "---\n",
    "\n",
    "**Note:** You will download and load these datasets in the respective sections below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2126b5de",
   "metadata": {},
   "source": [
    "<font face=\"Trebuchet MS\" color=\"gold\" size=\"+3\"><b>⚠️ ATTENTION</b></font><br>\n",
    "<font face=\"Trebuchet MS\" color=\"#FF6666\" size=\"+2\"><b>For each of the following questions, provide clear explanations, appropriate visualizations, and well-documented code to support your analysis and findings.</b></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9e8634",
   "metadata": {},
   "source": [
    "# Part I: Binary Classification - Heart Disease Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ed59051",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">1- Load and Explore the Heart Disease Dataset</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(4 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Load the heart disease dataset (you can use sklearn's built-in version or download from UCI repository)\n",
    "\n",
    "- Display the first few rows and basic information (shape, data types, missing values)\n",
    "\n",
    "- Generate summary statistics for all features\n",
    "\n",
    "- Visualize the distribution of the target variable (class balance)\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e693a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import kagglehub\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix, classification_report, \n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_curve, roc_auc_score, auc\n",
    ")\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Set style for better visualizations\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef925a33",
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load and explore the Heart Disease dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m HEART_DATA_URL \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/plotly/datasets/master/heart.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m heart_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mHEART_DATA_URL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheart_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m rows × \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mheart_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m columns\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m display(heart_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:728\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    725\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    727\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 728\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    729\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    731\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    732\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    733\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    734\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    736\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    737\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:384\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    383\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 384\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    385\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    386\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    387\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\io\\common.py:289\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    285\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    286\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 289\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhdrs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "# Load and explore the Heart Disease dataset\n",
    "heart_dataset_dir = Path(kagglehub.dataset_download(\"redwankarimsony/heart-disease-data\"))\n",
    "heart_csv = heart_dataset_dir / \"heart_disease_uci.csv\"\n",
    "if not heart_csv.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Expected heart dataset at {heart_csv}. Available files: {list(heart_dataset_dir.iterdir())}\"\n",
    "    )\n",
    "heart_df = pd.read_csv(heart_csv)\n",
    "\n",
    "print(f\"Loaded dataset from: {heart_csv}\")\n",
    "print(f\"Dataset shape: {heart_df.shape[0]} rows × {heart_df.shape[1]} columns\")\n",
    "display(heart_df.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\\n\")\n",
    "heart_df.info()\n",
    "\n",
    "display(heart_df.describe().T)\n",
    "\n",
    "target_counts = heart_df['target'].value_counts().sort_index()\n",
    "sns.barplot(x=target_counts.index, y=target_counts.values, palette=\"viridis\")\n",
    "plt.title('Heart Disease Target Distribution (0 = No Disease, 1 = Disease)')\n",
    "plt.xlabel('target')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329f54ab",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">2- Data Preprocessing</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Handle missing values (if any)\n",
    "\n",
    "- Check for outliers and decide how to handle them\n",
    "\n",
    "- Create a correlation matrix and visualize feature correlations\n",
    "\n",
    "- Perform feature scaling using StandardScaler\n",
    "\n",
    "- Split the data into training (70%), validation (15%), and test (15%) sets\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff374a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing pipeline\n",
    "heart_clean = heart_df.copy()\n",
    "\n",
    "print(\"Missing values per column:\")\n",
    "missing_summary = heart_clean.isna().sum()\n",
    "display(missing_summary.to_frame(name='missing_count'))\n",
    "\n",
    "# Handle outliers in continuous numeric columns using IQR-based clipping\n",
    "# Common column names in heart disease datasets (check which ones exist)\n",
    "possible_continuous_cols = ['age', 'trestbps', 'chol', 'thalach', 'oldpeak', \n",
    "                             'trest_bps', 'resting_bp', 'cholesterol', 'max_heart_rate']\n",
    "continuous_cols = [col for col in possible_continuous_cols if col in heart_clean.columns]\n",
    "# Also check for any numeric columns that might be continuous features\n",
    "if not continuous_cols:\n",
    "    numeric_cols = heart_clean.select_dtypes(include=[np.number]).columns\n",
    "    # Exclude target and binary/categorical columns\n",
    "    continuous_cols = [col for col in numeric_cols \n",
    "                       if col != 'target' and heart_clean[col].nunique() > 10]\n",
    "\n",
    "iqr_bounds = {}\n",
    "for col in continuous_cols:\n",
    "    if col in heart_clean.columns:\n",
    "        q1, q3 = heart_clean[col].quantile([0.25, 0.75])\n",
    "        iqr = q3 - q1\n",
    "        if iqr > 0:  # Avoid division issues\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "            heart_clean[col] = heart_clean[col].clip(lower=lower, upper=upper)\n",
    "            iqr_bounds[col] = (lower, upper)\n",
    "\n",
    "print(\"\\nApplied IQR clipping to:\")\n",
    "for col, bounds in iqr_bounds.items():\n",
    "    print(f\"- {col}: [{bounds[0]:.2f}, {bounds[1]:.2f}]\")\n",
    "\n",
    "# Correlation matrix visualization\n",
    "corr_matrix = heart_clean.corr()\n",
    "plt.figure(figsize=(14, 10))\n",
    "sns.heatmap(corr_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Feature scaling and train/val/test split (70% / 15% / 15%)\n",
    "feature_cols = heart_clean.columns.drop('target')\n",
    "X = heart_clean[feature_cols]\n",
    "y = heart_clean['target']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, stratify=y, random_state=RANDOM_STATE\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "split_summary = pd.DataFrame({\n",
    "    'Set': ['Train', 'Validation', 'Test'],\n",
    "    'Samples': [len(y_train), len(y_val), len(y_test)],\n",
    "    'Positive Rate': [y_train.mean(), y_val.mean(), y_test.mean()]\n",
    "})\n",
    "\n",
    "print(\"\\nDataset split summary:\")\n",
    "display(split_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c78ef3",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">3- Binary Classification with Random Forest</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(6 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Train a Random Forest classifier on the training set\n",
    "\n",
    "- Make predictions on the validation set\n",
    "\n",
    "- Calculate and display: Accuracy, Precision, Recall, and F1-Score\n",
    "\n",
    "- Create and visualize the confusion matrix\n",
    "\n",
    "- Interpret the confusion matrix: What do TP, TN, FP, FN mean in the context of heart disease diagnosis?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7954705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate a Random Forest classifier\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=400,\n",
    "    random_state=RANDOM_STATE,\n",
    "    class_weight=\"balanced_subsample\"\n",
    ")\n",
    "rf_clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_val_pred = rf_clf.predict(X_val_scaled)\n",
    "y_val_proba = rf_clf.predict_proba(X_val_scaled)[:, 1]\n",
    "\n",
    "val_metrics = {\n",
    "    \"Accuracy\": accuracy_score(y_val, y_val_pred),\n",
    "    \"Precision\": precision_score(y_val, y_val_pred),\n",
    "    \"Recall\": recall_score(y_val, y_val_pred),\n",
    "    \"F1-Score\": f1_score(y_val, y_val_pred)\n",
    "}\n",
    "\n",
    "print(\"Random Forest validation performance:\")\n",
    "display(pd.DataFrame(val_metrics, index=[\"Validation\"]))\n",
    "\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    cbar=False,\n",
    "    xticklabels=[\"Pred 0\", \"Pred 1\"],\n",
    "    yticklabels=[\"Actual 0\", \"Actual 1\"]\n",
    ")\n",
    "plt.title(\"Heart Disease Validation Confusion Matrix\")\n",
    "plt.ylabel(\"Actual label\")\n",
    "plt.xlabel(\"Predicted label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b603594",
   "metadata": {},
   "source": [
    "```\n",
    "True Positives (TP) correspond to patients correctly flagged as having heart disease, meaning the model supports timely intervention. True Negatives (TN) are healthy patients correctly reassured. False Positives (FP) are healthy patients incorrectly flagged, potentially causing unnecessary stress and follow-up tests. False Negatives (FN) are the riskiest case—patients with disease that the model misses—since they may leave without needed treatment. Ideally we minimize FN even at the cost of a few more FP.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5939d479",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">4- Understanding Precision, Recall, and F1-Score</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Explain the formulas for Precision, Recall, and F1-Score\n",
    "\n",
    "- In the context of heart disease prediction, which metric is more important: Precision or Recall? Why?\n",
    "\n",
    "- Calculate these metrics manually from the confusion matrix and verify they match sklearn's output\n",
    "\n",
    "- Discuss the trade-off between Precision and Recall\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2818b05",
   "metadata": {},
   "source": [
    "```\n",
    "Precision = TP / (TP + FP) measures how many predicted positives are truly positive. Recall = TP / (TP + FN) captures how many actual positives we correctly detect. F1 = 2 * (Precision * Recall) / (Precision + Recall) balances both terms. In heart-disease screening, Recall is typically more critical because missing a sick patient (FN) could delay lifesaving care, whereas an extra FP usually results in an additional test. Still, we track Precision to keep unnecessary follow-ups manageable. To verify our understanding, we can recompute these metrics directly from the confusion matrix and compare them with sklearn's report. The expected trade-off is that increasing Recall (lower threshold) usually decreases Precision because more borderline cases are labeled positive; tightening the threshold does the opposite. Choosing the right operating point depends on acceptable clinical risk.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca14b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually verify precision, recall, and F1 using the confusion matrix\n",
    "TN, FP, FN, TP = cm.ravel()\n",
    "manual_precision = TP / (TP + FP)\n",
    "manual_recall = TP / (TP + FN)\n",
    "manual_f1 = 2 * (manual_precision * manual_recall) / (manual_precision + manual_recall)\n",
    "\n",
    "print(\"Confusion matrix counts:\")\n",
    "print({\"TN\": TN, \"FP\": FP, \"FN\": FN, \"TP\": TP})\n",
    "print(\"\\nManual metrics vs. sklearn:\")\n",
    "verification_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Manual\": [manual_precision, manual_recall, manual_f1],\n",
    "        \"sklearn\": [val_metrics[\"Precision\"], val_metrics[\"Recall\"], val_metrics[\"F1-Score\"]]\n",
    "    },\n",
    "    index=[\"Precision\", \"Recall\", \"F1\"]\n",
    ")\n",
    "display(verification_df)\n",
    "\n",
    "print(\"Absolute differences:\")\n",
    "display((verification_df[\"Manual\"] - verification_df[\"sklearn\"]).abs())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56894675",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">5- ROC Curve and AUC Score</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(6 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Plot the ROC (Receiver Operating Characteristic) curve for your Random Forest model\n",
    "\n",
    "- Calculate and display the AUC (Area Under Curve) score\n",
    "\n",
    "- Explain what the ROC curve represents and how to interpret it\n",
    "\n",
    "- What does an AUC score of 0.5 vs 1.0 indicate?\n",
    "\n",
    "- Find the optimal threshold on the ROC curve that balances sensitivity and specificity\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237f3699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve, AUC, and optimal threshold selection\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_proba)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "youden_index = tpr - fpr\n",
    "best_idx = np.argmax(youden_index)\n",
    "best_threshold = thresholds[best_idx]\n",
    "best_sensitivity = tpr[best_idx]\n",
    "best_specificity = 1 - fpr[best_idx]\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "plt.plot(fpr, tpr, label=f\"ROC curve (AUC = {roc_auc:.3f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\", label=\"Random guess\")\n",
    "plt.scatter(fpr[best_idx], tpr[best_idx], color=\"red\", s=60,\n",
    "            label=(\n",
    "                f\"Best threshold={best_threshold:.2f}\\n\"\n",
    "                f\"TPR={best_sensitivity:.2f}, TNR={best_specificity:.2f}\"\n",
    "            ))\n",
    "plt.xlabel(\"False Positive Rate (1 - Specificity)\")\n",
    "plt.ylabel(\"True Positive Rate (Sensitivity)\")\n",
    "plt.title(\"ROC Curve - Validation Set\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"AUC score: {roc_auc:.3f}\")\n",
    "print(f\"Optimal threshold by Youden's J statistic: {best_threshold:.3f}\")\n",
    "print(f\"Sensitivity at optimal threshold: {best_sensitivity:.3f}\")\n",
    "print(f\"Specificity at optimal threshold: {best_specificity:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9365b2b7",
   "metadata": {},
   "source": [
    "```\n",
    "The ROC curve traces every possible probability threshold, showing how sensitivity (TPR) increases as we accept more false alarms (FPR). Curves that hug the top-left indicate strong discrimination, while the diagonal represents random guessing. The AUC aggregates this behavior: 0.5 ≈ random, 1.0 is perfect separation. Our AUC > 0.8 shows solid predictive power. Selecting the Youden point maximizes (TPR − FPR), giving a balanced threshold where sensitivity and specificity are both high—useful when we want good recall without overwhelming clinicians with false positives.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13740c28",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">6- Cross-Validation</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(4 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Explain what cross-validation is and why it's important\n",
    "\n",
    "- Implement k-fold cross-validation (k=5) on your Random Forest model\n",
    "\n",
    "- Report the mean and standard deviation of the accuracy scores across all folds\n",
    "\n",
    "- Compare the cross-validation results with your single train-validation split results\n",
    "\n",
    "- Discuss the advantages and disadvantages of cross-validation\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa972a80",
   "metadata": {},
   "source": [
    "```\n",
    "Cross-validation partitions the data into k folds, training on k−1 folds and validating on the remaining fold repeatedly. It reduces variance in our performance estimate and ensures every sample gets used for validation. Compared with a single train/validation split, CV is slower but provides a more reliable picture, especially with limited data. Its drawbacks are higher compute cost and potential leakage if preprocessing is not nested inside the folds, so we wrap scaling and modeling in a pipeline. After running 5-fold CV we can compare the mean accuracy (and its standard deviation) with the single validation score to see whether our hold-out split was optimistic or pessimistic.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae88a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5-fold cross-validation with scaling inside the pipeline\n",
    "rf_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"rf\", RandomForestClassifier(\n",
    "            n_estimators=400,\n",
    "            random_state=RANDOM_STATE,\n",
    "            class_weight=\"balanced_subsample\"\n",
    "        ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "cv_scores = cross_val_score(rf_pipeline, X, y, cv=5, scoring=\"accuracy\")\n",
    "\n",
    "print(\"Cross-validation accuracy scores:\")\n",
    "print(cv_scores)\n",
    "print(f\"Mean accuracy: {cv_scores.mean():.3f} ± {cv_scores.std():.3f}\")\n",
    "print(f\"Single validation accuracy: {val_metrics['Accuracy']:.3f}\")\n",
    "\n",
    "if cv_scores.mean() > val_metrics['Accuracy']:\n",
    "    comparison = \"slightly optimistic\"\n",
    "else:\n",
    "    comparison = \"slightly conservative\"\n",
    "print(f\"The hold-out split appears {comparison} relative to the CV mean.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58d2a9c",
   "metadata": {},
   "source": [
    "# Part II: Multiclass Classification - Wine Quality Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e396e884",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">7- Load and Explore the Wine Quality Dataset</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(4 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Load the wine quality dataset (available from UCI or sklearn)\n",
    "\n",
    "- Display basic information and summary statistics\n",
    "\n",
    "- Visualize the distribution of wine quality ratings (target variable)\n",
    "\n",
    "- Check for class imbalance and discuss potential issues\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c50fb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the Wine Quality dataset\n",
    "wine_csv = Path(\"uci-wine-quality-dataset/winequality-data.csv\")\n",
    "if not wine_csv.exists():\n",
    "    raise FileNotFoundError(f\"Wine dataset not found at {wine_csv}\")\n",
    "wine_df = pd.read_csv(wine_csv)\n",
    "\n",
    "print(f\"Loaded dataset from: {wine_csv}\")\n",
    "print(f\"Dataset shape: {wine_df.shape[0]} rows × {wine_df.shape[1]} columns\")\n",
    "display(wine_df.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\\n\")\n",
    "wine_df.info()\n",
    "\n",
    "print(\"\\nSummary statistics:\\n\")\n",
    "display(wine_df.describe().T)\n",
    "\n",
    "# Visualize the distribution of wine quality ratings\n",
    "quality_counts = wine_df['quality'].value_counts().sort_index()\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=quality_counts.index, y=quality_counts.values, palette=\"viridis\")\n",
    "plt.title('Wine Quality Distribution')\n",
    "plt.xlabel('Quality Rating')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Check for class imbalance\n",
    "print(f\"\\nClass distribution:\\n{quality_counts}\")\n",
    "print(f\"\\nClass imbalance ratio (min/max): {quality_counts.min() / quality_counts.max():.3f}\")\n",
    "print(\"\\nPotential issues:\")\n",
    "print(\"- Classes with very few samples may be harder to predict accurately\")\n",
    "print(\"- Imbalanced classes can lead to models that favor majority classes\")\n",
    "print(\"- Consider using class weights or resampling techniques if imbalance is severe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663fab4f",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">8- Multiclass Classification with Multiple Algorithms</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(8 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "Train and evaluate at least 4 different classification algorithms:\n",
    "\n",
    "- Naive Bayes (GaussianNB)\n",
    "- Support Vector Machine (SVC)\n",
    "- Stochastic Gradient Descent Classifier (SGDClassifier)\n",
    "- Random Forest\n",
    "\n",
    "For each model:\n",
    "- Train on the training set\n",
    "- Evaluate on the validation set\n",
    "- Report accuracy, precision, recall, and F1-score (use macro and weighted averages)\n",
    "- Create a comparison table of all models\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b57a84b",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">9- Confusion Matrix Analysis for Multiclass</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(6 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Create and visualize the confusion matrix for your best-performing model\n",
    "\n",
    "- Analyze the confusion matrix: Which classes are most confused with each other?\n",
    "\n",
    "- Calculate per-class precision and recall\n",
    "\n",
    "- Discuss why certain classes might be harder to predict than others\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348d096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214c83f1",
   "metadata": {},
   "source": [
    "```\n",
    "[Your analysis here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7dfe05",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">10- One-vs-Rest (OvR) Strategy</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Explain the One-vs-Rest (OvR) strategy for multiclass classification\n",
    "\n",
    "- Implement a binary classifier using OvR with OneVsRestClassifier wrapper\n",
    "\n",
    "- Compare the results with the native multiclass implementation\n",
    "\n",
    "- Discuss when OvR might be preferred over native multiclass algorithms\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c8d0f2",
   "metadata": {},
   "source": [
    "```\n",
    "[Your answer here]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed88b7",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">11- Hyperparameter Tuning with Grid Search</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(6 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Select your best-performing algorithm from Question 8\n",
    "\n",
    "- Define a parameter grid with at least 3 hyperparameters\n",
    "\n",
    "- Use GridSearchCV with 5-fold cross-validation to find optimal hyperparameters\n",
    "\n",
    "- Report the best parameters and the improvement in performance\n",
    "\n",
    "- Visualize how different hyperparameter values affect model performance\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba10865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cadb991d",
   "metadata": {},
   "source": [
    "# Part III: Multilabel Classification - Movie Genre Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b97aa1",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">12- Create/Load Multilabel Dataset</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "**Option A:** Use sklearn's make_multilabel_classification to create a synthetic dataset\n",
    "\n",
    "**Option B:** Load a real multilabel dataset (e.g., movie genres, text categorization)\n",
    "\n",
    "- Create/load a multilabel classification dataset with at least 5 labels\n",
    "\n",
    "- Display the first few samples\n",
    "\n",
    "- Analyze label distribution and co-occurrence patterns\n",
    "\n",
    "- Visualize label correlations using a heatmap\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d45bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and explore the Movie Genre Dataset (multilabel)\n",
    "movie_dataset_dir = Path(kagglehub.dataset_download(\"harshitshankhdhar/imdb-dataset-of-top-1000-movies-and-tv-shows\"))\n",
    "movie_files = list(movie_dataset_dir.glob(\"*.csv\"))\n",
    "if not movie_files:\n",
    "    raise FileNotFoundError(\n",
    "        f\"No CSV files found in {movie_dataset_dir}. Available files: {list(movie_dataset_dir.iterdir())}\"\n",
    "    )\n",
    "movie_csv = movie_files[0]  # Use the first CSV file found\n",
    "movie_df = pd.read_csv(movie_csv)\n",
    "\n",
    "print(f\"Loaded dataset from: {movie_csv}\")\n",
    "print(f\"Dataset shape: {movie_df.shape[0]} rows × {movie_df.shape[1]} columns\")\n",
    "display(movie_df.head())\n",
    "\n",
    "print(\"\\nDataFrame info:\\n\")\n",
    "movie_df.info()\n",
    "\n",
    "print(\"\\nColumn names:\")\n",
    "print(movie_df.columns.tolist())\n",
    "\n",
    "# Check for genre columns (multilabel targets)\n",
    "# Common genre column patterns: 'Genre', 'genres', or separate genre columns\n",
    "genre_cols = [col for col in movie_df.columns if 'genre' in col.lower() or 'Genre' in col]\n",
    "print(f\"\\nPotential genre columns: {genre_cols}\")\n",
    "\n",
    "# Display first few samples with genre information\n",
    "if genre_cols:\n",
    "    print(\"\\nSample movies with genres:\")\n",
    "    display(movie_df[['Title', 'Genre']].head(10) if 'Title' in movie_df.columns and 'Genre' in movie_df.columns \n",
    "            else movie_df[genre_cols].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c98674",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">13- Understanding Multilabel Classification</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(4 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Explain the difference between multiclass and multilabel classification\n",
    "\n",
    "- Provide real-world examples of multilabel classification problems\n",
    "\n",
    "- Discuss the challenges specific to multilabel classification\n",
    "\n",
    "- Explain how evaluation metrics differ for multilabel problems\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb18f91",
   "metadata": {},
   "source": [
    "```\n",
    "[Your answer here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52cf31cc",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">14- Multilabel Classification with KNN</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(6 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Implement a K-Nearest Neighbors classifier for multilabel classification\n",
    "\n",
    "- Train the model and make predictions on the validation set\n",
    "\n",
    "- Calculate multilabel evaluation metrics:\n",
    "  - Hamming Loss\n",
    "  - Subset Accuracy\n",
    "  - Precision, Recall, F1-Score (micro, macro, samples averages)\n",
    "\n",
    "- Visualize the predicted vs actual labels for a sample of instances\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09c068b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88323ee4",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">15- Classifier Chains</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(6 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Explain how Classifier Chains work for multilabel classification\n",
    "\n",
    "- Implement a ClassifierChain with a base classifier of your choice\n",
    "\n",
    "- Compare the performance of ClassifierChain with the independent KNN approach\n",
    "\n",
    "- Discuss the advantages and disadvantages of Classifier Chains\n",
    "\n",
    "- Experiment with different chain orders and analyze the impact\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f488b24",
   "metadata": {},
   "source": [
    "```\n",
    "[Your answer here]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7507fb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d80910",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">16- Per-Label Analysis</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Calculate precision, recall, and F1-score for each individual label\n",
    "\n",
    "- Create a visualization comparing per-label performance\n",
    "\n",
    "- Identify which labels are easiest/hardest to predict and explain why\n",
    "\n",
    "- Analyze the relationship between label frequency and prediction performance\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf37d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5e6dfe",
   "metadata": {},
   "source": [
    "# Part IV: Comprehensive Comparison and Final Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b18f4e",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">17- Model Comparison Across All Tasks</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Create a comprehensive comparison table of your best models for:\n",
    "  - Binary classification (Heart Disease)\n",
    "  - Multiclass classification (Wine Quality)\n",
    "  - Multilabel classification (Movie Genres)\n",
    "\n",
    "- Include relevant metrics for each task type\n",
    "\n",
    "- Discuss the differences in model selection and evaluation across these three problem types\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082cc3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64232dc3",
   "metadata": {},
   "source": [
    "```\n",
    "[Your analysis here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8ab677",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">18- Final Model Testing</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "- Select your best model from each of the three classification tasks\n",
    "\n",
    "- Evaluate each model on the held-out test set (that was not used during training or validation)\n",
    "\n",
    "- Report final test performance metrics\n",
    "\n",
    "- Compare test set performance with validation set performance\n",
    "\n",
    "- Discuss any signs of overfitting or underfitting\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95e67ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4264bfa",
   "metadata": {},
   "source": [
    "```\n",
    "[Your analysis here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18cab110",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">19- Error Analysis and Insights</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(10 points - BONUS)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "For each classification task:\n",
    "\n",
    "- Identify and analyze specific misclassified examples\n",
    "\n",
    "- Discuss potential reasons for these errors\n",
    "\n",
    "- Suggest possible improvements or additional features that could help\n",
    "\n",
    "- Discuss the practical implications of these errors in real-world applications\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf9dbc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e8dff",
   "metadata": {},
   "source": [
    "```\n",
    "[Your analysis here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b61a04",
   "metadata": {},
   "source": [
    "<font face=\"Courier New\" color=\"orange\" size=\"+3\">20- Key Takeaways and Reflections</font> <font face=\"Courier New\" color=\"lightblue\" size=\"+3\">(5 points)</font>\n",
    "\n",
    "<font face=\"Courier New\" size=\"+1\"> \n",
    "\n",
    "Provide a comprehensive summary addressing:\n",
    "\n",
    "- What are the key differences between binary, multiclass, and multilabel classification?\n",
    "\n",
    "- Which evaluation metrics are most important for each type of problem?\n",
    "\n",
    "- What did you learn about model selection and hyperparameter tuning?\n",
    "\n",
    "- Discuss 3 real-world applications where each classification type would be most appropriate\n",
    "\n",
    "- What were the biggest challenges you faced in this assignment?\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edcffbe",
   "metadata": {},
   "source": [
    "```\n",
    "[Your reflections here]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9555d062",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Congratulations on completing ML02! 🎉\n",
    "\n",
    "You have successfully worked through binary, multiclass, and multilabel classification problems, gaining hands-on experience with:\n",
    "- Cross-validation techniques\n",
    "- Confusion matrix analysis\n",
    "- Precision, Recall, and F1-Score evaluation\n",
    "- ROC curves and AUC metrics\n",
    "- Random Forest and multiple classification algorithms\n",
    "- Hyperparameter tuning\n",
    "- Multilabel classification approaches\n",
    "\n",
    "**Remember to:**\n",
    "1. Save your notebook with the correct naming format\n",
    "2. Ensure all code cells run without errors\n",
    "3. Include clear explanations and visualizations\n",
    "4. Submit before the deadline via Microsoft Teams\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
